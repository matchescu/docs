In scientific literature, entity resolution has been attributed numerous
characteristics\cite{Tal11,Pap19}.
In the context of this paper, the following stand out:

\begin{itemize}
    \item\textit{A concern for a real-world entity}, for if the task were
    not about a something from our world, there couldn't be any resolution;
    \item\textit{No implication as to the used method}, because if we
    stipulated a certain way to perform entity resolution, we might not be
    able to;
    \item\textit{The representation of information is computer friendly},
    because if it weren't, it might not be possible to study the task by
    means of computer science.
\end{itemize}

The first two statements suggest that entity resolution can be performed
using any informational support.
Simply imagine collecting written notes about the same real-world object to
create an informational profile of that object.
Entity resolution becomes relevant to computer science when it involves
processing information about real-world entities through computational
methods, rather than directly interacting with the entities
themselves~\cite{Tal11}.
This approach is characterized by the constraint of handling data that is
computable, indicating that entity resolution tasks executed on computers
do not have direct access to the entities they aim to resolve~\cite{Chen09}.

Whenever we talk about measuring the performance of an entity resolution
task, we must note that we are confined to the information that is available
to the computer running the task.
On the other hand, as humans we judge the quality of the entity resolution
task's result in relation to the real-world information available to us, which
usually includes the real-world object itself.
This produces a gap between what a computer can provide us with and the human
observer's expectation, a gap which is starting to garner attention~\cite{wang2022realideal}.
Coincidentally we are nearing a century since it has become apparent that the
observer is key in our physical universe~\cite{schrodinger1926}.
Perhaps we can find inspiration for understanding entity resolution quality in
Schrodinger's insight.

There are multiple models that describe entity resolution.
Each theoretical model's job is to describe something (in our case, entity
resolution) using existing notions.
Some use probabilities, some use linear algebra and some use graphs.
All of them describe entity resolution completely.
The depth at which they are able to describe entity resolution depends on the
allowances of the tools they use.
Entity resolution is described better by richer data structures and more complex
processes.
To this end, entity resolution models make up two main families: matching models
and clustering models.
Our intent is to relate two models from each family.

In this context, we may find conditions that originate in the entity resolution
model itself rather than in reality, the data provided to the computer or the
entity resolution solution.
These conditions might be abstract, but they might also provide valuable
insight to the human observer that analyses an entity resolution outcome.
Our \textbf{main goal is to find out whether such invariant conditions might
actually exist}.

Next, another gap presents itself between the generic solutions provided by
scientific literature or programming libraries and the specific needs derived
from a context of the practitioners actually implementing entity resolution
systems.

Historically, entity resolution measurements owe much to the field of
information retrieval and to statistics.
Implementing entity resolution systems in practice, we often notice that
using popular metrics borrowed from these fields (such as the $F_1$ score) we
end up overlooking some essential aspect.
For example, in anomaly detection problems we are primarily interested in
sensitivity, not the balanced outlook the $F_1$ score provides.

Choosing an entity resolution solution remains a necessary step in adopting an
entity resolution system.
The longer it takes to find one, the higher the implementation costs.

Papers have been published on the biases inherent in certain metrics
and how they influence judging entity resolution outcomes in a specific
context~\cite{Goga2015}.
Most entity resolution systems do not provide easy means of verifying entity
resolution quality~\cite{fever2009,oyster2012,jedai2017,magellan2020}.
The few systems out there that do provide some form of ranking entity
resolution solutions tend to use very few metrics~\cite{papwithcode2019}.
Projects to bridge this gap are emerging~\cite{matchescu-er-metrics2023}.

On the other hand, the myriad ways~\cite{hitesh2012} in which we can evaluate
entity resolution quality suggests that we haven't found the ideal perspective
for the entity resolution problem.
If we were to calibrate an entity resolution solution today, we might not have 
the necessary insight readily available.
From this point of view, it seems logical to look at \textbf{how we might use
existing metrics more effectively, by finding complementary metrics that enhance
our understanding of the results produced by entity resolution solutions}.

Quality metrics for entity matching (used here to signify `basic comparison
between two information') dominate entity resolution quality
evaluation~\cite{fever2009,Men10,Goga2015}.
Their origin in information retrieval and probability theory makes them easier
to understand and more convenient to work with.
Metrics originally designed to aid in graph theory problems have become useful,
too~\cite{hitesh2012,Kon19}.
In describing entity resolution as a clustering problem~\cite{Tal11}, quality
metrics that go beyond matching~\cite{Men10,tal2007algebraic} are revealed.

If entity resolution models describe entity resolution itself, metrics evaluate
evaluate entity resolution results.
Assuming certain metrics linked to certain models, our final research question
is \textbf{whether it's possible to interpret the same entity resolution task
using different entity resolution models}.
