\documentclass[journal]{IEEEtran}

% Packages
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{algorithmic}
\usepackage{balance}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{array}
\usepackage{graphicx}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\graphicspath{ {./img/} }
\newcommand{\BibTeX}{\textrm{B \kern-.05em \textsc{i \kern-.025em b} \kern-.08em
T \kern-.1667em \lower.7ex \hbox{E} \kern-.125emX}}
\usepackage{balance}

% Document
\begin{document}
    \title{A Tale of Two Entity Resolution Models}
    % \author{Andrei Olar \textcolor{green}{eu m-as bucura sa ma incluzi si pe mine; daca este de acord poti formata ca mai jos partea de autori}}
    \author{
        \IEEEauthorblockN{
            Andrei Olar\IEEEauthorrefmark{1},
            Laura Dio\c san\IEEEauthorrefmark{2}
        }
        \IEEEauthorblockA{
            Faculty of Mathematics and Computer Science, Babe\c s-Bolyai University\\
            Email: 
                \IEEEauthorrefmark{1}andrei.olar@ubbcluj.ro,
                \IEEEauthorrefmark{2}laura.diosan@ubbcluj.ro
        }
    }

    \maketitle

    \theoremstyle{definition}
    \newtheorem{defn}{Definition}[section]
    
    \maketitle
    \begin{abstract}
        This paper examines entity resolution, the process of identifying if two
        information represent the same real-world entity.
        Despite well-established theoretical models in this field, challenges
        persist in selecting appropriate entity resolution tasks for specific
        contexts.
        These models are associated with quality metrics that assess the
        outcomes of entity resolution tasks.
        Our study demonstrates the possibility of identifying abstract
        conditions invariant to specific solutions and data sets, which instead
        relate to the theoretical model used for evaluating entity resolution
        outcomes.
        This approach offers a novel perspective for understanding the
        performance of entity resolution tasks.
    \end{abstract}

    \begin{IEEEkeywords}
        Entity Resolution, Fellegi-Sunter, Algebraic Model, Metrics, Evaluation
    \end{IEEEkeywords}

    \section{Introduction}\label{sec:introduction}
    Entity resolution is the task of determining whether two information refer
    to the same real-world item or not.
    More restrictive definitions place entity resolution as the task of
    identifying and linking representations of data from two or more
    sources~\cite{Qia17}.
    However, we share the opinion that identifying and linking data constitutes
    a more specialized process~\cite{Tal11}.
    The task of gathering information about a generic pound of potatoes across
    various marketplaces is still an entity resolution task, in our view.
    Whether the information about marketplaces and the potatoes that find
    themselves passing through there is available in one or more places strikes
    us as non-consequential, too.
    Besides not talking about identity problems, we also leave aside any
    classification of entity resolution algorithms based on number of sources.
    
    Precisely because it is a fundamental problem, entity resolution goes by
    many names: record linkage, data de-duplication, merge-purge, named entity
    recognition and disambiguation (or NERD), entity alignment or entity
    matching~\cite{Tal11,fever2009,alhelbawy2014}.
    The number of names is matched by the number of practical applications for
    entity resolution, ranging from linking medical records to assisting in
    medical diagnostics, to translation, to doing background checks for
    financial crime or to identifying plagiarism.
    Combining information from different media (sound, images, motion, smell,
    etc.) can also be regarded as a form of entity resolution when the purpose
    is to gather more information about the same real-world object.
    With such a wide array of past, present and future applications for entity
    resolution, evaluating its quality seems important.

    With the current paper, our goal is to introspect how entity resolution
    theoretical models influence our perception over entity resolution results.
    The discussion is around choosing entity resolution solutions that are
    more or less suitable based on how we perceive their outcomes.
    In this context, we are interested in how entity resolution quality metrics
    complement one another.
    Partly in order to answer this last question, we are looking into the
    diversity of the insights provided by different entity resolution models
    regarding the same entity resolution result.
    
    We begin with a preliminary description focused on further detailing the
    goals of this paper.
    After briefly summarizing the work that relates to our paper, we introduce
    terminology and a mental model that we use throughout the remaining
    sections.
    Afterwards, we revisit the two theoretical models for entity resolution
    chosen for our analysis.
    The text describing theoretical models is accompanied by experiments using
    an entity resolution solution of choice for which we present our findings.
    We discuss our observations, pointing out invariant conditions that do not
    seem to be related to the choice of data set.

    \section[preliminaries-questions]{Preliminaries \& Research Questions}
    \label{sec:preliminaries-questions}
    \input{research-questions}

    \section{Related Work}\label{sec:related}
    
    The topic addressed in this paper intersects with a significant body of
    existing research.
    Specifically, it aligns closely with three primary categories: presentations
    of entity resolution systems, theoretical model syntheses for entity
    resolution, and analyses of evaluation metrics in the field of entity
    resolution.

    Papers introducing entity resolution systems are relevant to this study due
    to their common objective of standardizing entity resolution tasks and their
    evaluation methods.
    The majority of the referenced systems in this context offer several generic
    metrics for assessing entity resolution performance.

    At the dawn of the 21st century AD, FEBRL~\cite{febrl2002} emerged as one of
    the first extensible systems to tackle measuring entity resolution
    performance.
    It was succeeded by FEVER~\cite{fever2009} and OYSTER~\cite{oyster2012}.
    These systems have all paved the way to generalizing our understanding about
    entity resolution and to ever more improvements in the quality of entity
    resolution tasks.
    Later on, systems like `Papers with Code'~\cite{papwithcode2019} brought in
    a social dimension to how we compare the qualitative performance of entity
    resolution tasks.
    The systems that came after, resemble frameworks more than they resemble
    applications~\cite{magellan2020,jedai2017}.
    Almost all systems are open-source and encourage social collaboration around
    entity resolution, too.
    
    Next, the syntheses on the theoretical models for entity
    resolution~\cite{fs1969,Ben2009Swoosh,Tal11} are invaluable resources.
    The models we present in this paper have been heavily documented
    elsewhere~\cite{Tal11,tal2013}.    
    We overview the models here to fill potential gaps in the reading flow of
    the paper more than to address another need.
    
    Taking a different tack on describing entity resolution in a generic,
    abstract way, there are studies that shine a procedural light over entity
    resolution~\cite{Pap19,Chen09}.
    These studies showcase the steps of the entity resolution process and the
    significance, challenges and benefits of each step.
    These studies show us that matching and clustering (additionally to being
    aspects of entity resolution) are steps in the entity resolution process.

    Lastly, we note syntheses that present numerous entity resolution metrics
    and their application~\cite{hitesh2012,graf2021frost,barnes2015practioner}.
    The current paper is very similar to these syntheses because it, too
    enumerates metrics and it, too attempts to use those metrics to gather
    deeper insights that would alleviate the burden of adopting entity
    resolution.
    We use this work to find the strongest associations of certain metrics with
    an entity resolution model.
    However, our approach is to discern between theoretical models and attempt
    to extract invariant conditions rooted in the model instead of simply using
    the metrics to evaluate the entity resolution result.

    \section{Theoretical background}
    \subsection[terminology]{Terminology pre-requisites}\label{sec:terminology}
    \input{terminology}
    
    \subsection{Formalizing Entity Resolution}\label{sec:entity-resolution}
    \input{formalization}

    \subsection[models]{Entity Resolution Models}\label{sec:models}

    The representation of entity resolution results depends upon the theoretical
    model we use.
    There are multiple theoretical models available for entity resolution and
    they range from ones based on complex networks and graph theory\cite{Li2020}
    to ones based on probabilities\cite{fs1969} or
    algebra\cite{Tal11,Ben2009Swoosh}.

    John R. Talburt provides an overview of these models in his book ``Entity
    Resolution and Information Quality''\cite{Tal11}.
    The main models presented there are the Fellegi-Sunter~\cite{fs1969} model,
    the Stanford Entity Resolution Framework~\cite{Ben2009Swoosh} model and the
    algebraic\cite{tal2007algebraic} model.
    This paper aims to analyse two of the models described in that book with an
    aim to understand how they influence our ability to measure the quality of
    entity resolution.

    The Fellegi-Sunter model is the best known model for entity resolution.
    Most of quality evaluations in the entity resolution space are made using
    probabilistic metrics defined by this model.
    When measuring results using these metrics, a common experience is not being
    able to fully explain how the quality of the results output by a particular
    entity resolution process varies with the data sets the process operates on.
    A common attitude towards this lack of understanding is to chalk things off
    to the characteristics of the underlying data and the size of the dataset.
    This paper attempts to find out if there aren't some things we might be able
    to infer regardless of those two qualities of the underlying data.

    The second model this paper looks into is the elegant algebraic model.
    The metrics we most strongly associate with this model should be very
    familiar to data clustering afficionados.
    It seems to be a good complement for the Fellegi-Sunter model.

    Additionally to presenting the two models, the question of whether they can
    be used in conjunction to analyse the same result needs an answer.
    The paper describes how an observer can switch from a probabilistic
    perspective on entity resolution to an algebraic one.

    The complexity of the discussion and the presentational space required,
    force us to leave the Stanford Entity Resolution Framework model out of the
    conversation for the time being.
    This means that we won't go into the metrics that are more commonly linked
    to it either, such as the generalized merged distance, the basic merge
    distance or variation of information~\cite{Men10}.

    \subsubsection[fsm]{Fellegi-Sunter Model}\label{subsec:fsm}
    \input{fsm}

    \subsubsection[algebraic]{Algebraic Model}\label{subsec:algebraic}
    \input{algebraic}

    \subsubsection{From Probabilities to Algebra}\label{subsec:fsm-alg}
    \input{convert}
        
    \section{Experiments}\label{sec:experiments}
    \input{experiments}

    \section[conclusion]{Conclusions}\label{sec:conclusions}

    Entity resolution is a complex task that still holds many unknowns.
    When evaluating entity resolution results in practice it often happens that
    the results on control data sets are not the same as the results obtained
    on `real-world' data.
    In the end, those results speak about certain expectations that stem from
    the way we interpret data.

    We set out on a journey to find out whether entity resolution models might
    provide an answer.
    Entity resolution models can be understood in many ways.
    Our own perception is that entity resolution models are simply theoretical
    perspectives over the practical act of determining whether two entity
    references refer to the same real-world entity.

    Depending on the entity resolution model, we saw that we may have different
    data structures to take into account when running an entity resolution
    process: from lists of pairs to partitions over a set.
    Depending on the perspective and the data structures we choose, we can say
    different things about the data we analyse.
    We posited that we can even change our point of view from one perspective to
    another without any data loss.

    Lastly, our experiment setup was designed to find invariant conditions that
    might help reduce the time of picking a good entity resolution algorithm
    configuration by leveraging entity resolution models.
    One such condition is that \textbf{probabilistic recall is always going to
    be distorted when the size of the entity resolution result is much greater
    than the size of the ground truth.}
    Luckily, pairwise recall is the perfect antidote for this distortion.
    Probabilistic metrics might be cheap and easy to use, but use pairwise
    metrics when in doubt.

    Another invariant is that \textbf{cluster precision is a good counterweight
    to probabilistic and pairwise precision.}
    This leads to cluster metrics forming a harmonious complement to
    probabilistic metrics, pairwise metrics and to the Adjusted Rand Index (ARI)
    which is also pair-based.
    
    This leads us to our third invariant: \textbf{the Talburt-Wang Index and the
    cluster metrics on one side and the Adjusted Rand Index on the other usually
    agree only when there is a good balance between precision and recall.}
    That means that the configuration value intervals where these metrics agree
    on a control data set provides us with a good estimation of the best
    configuration options for running an entity resolution algorithm.
    These configurations seem to hold true irrespective of the data we run
    entity resolution on.

    % \section[future]{Future Work}\label{sec:future}

    The current paper covers only two models and there are more to cover.
    Existing models such as the one proposed by the Stanford Entity Resolution
    Framework\cite{Ben2009Swoosh} or graph theoretical models used frequently in
    entity alignment tasks are prime candidates.
    On the other hand, we can also propose new models based on recent
    developments in the field of machine learning and artificial intelligence.

    From an experimental perspective, we can expand our experiment base using
    more and more algorithms to find out whether the conjectures outlined in
    the current paper are worth proving formally.
    The other aspect that is left unresolved is the claim that probabilistic
    recall provides a distorted interpretation over the entity resolution result
    when the result size is significantly larger than the ground truth.
    Albeit challenging, experiments to verify this claim can and should be
    designed.

    Lastly, another significant dimension of entity resolution refers to the
    quantitative measurement of performance.
    Entity resolution is usually an expensive process in terms of computational
    resources.
    A solution that balances well the outcome quality with performance is
    desirable.


    \balance

    \bibliographystyle{ieeetr}
    \bibliography{er-general,er-related-work,er-additional-references,er-software}
\end{document}
