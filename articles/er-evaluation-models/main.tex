\documentclass[journal]{IEEEtran}

% Packages
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{algorithmic}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{array}
\usepackage{graphicx}
\usepackage{balance}
\usepackage{caption}

\captionsetup[table]{skip=6pt}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\graphicspath{ {./img/} }
\newcommand{\BibTeX}{\textrm{B \kern-.05em \textsc{i \kern-.025em b} \kern-.08em
T \kern-.1667em \lower.7ex \hbox{E} \kern-.125emX}}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

% Document
\begin{document}
    \title{A Tale of Two Entity Resolution Models}
    \author{
        \IEEEauthorblockN{
            Andrei Olar\IEEEauthorrefmark{1},
            Laura Dio\c san\IEEEauthorrefmark{2}
        }
        \IEEEauthorblockA{
            Faculty of Mathematics and Computer Science, Babe\c s-Bolyai University\\
            Email: 
                \IEEEauthorrefmark{1}andrei.olar@ubbcluj.ro,
                \IEEEauthorrefmark{2}laura.diosan@ubbcluj.ro
        }
    }

    \maketitle

    \theoremstyle{definition}
    \newtheorem{defn}{Definition}[section]
    
    \maketitle
    \begin{abstract}
        This paper examines entity resolution, the process of identifying if two
        information represent the same real-world entity.
        Despite well-established theoretical models in this field, challenges
        persist in selecting appropriate entity resolution tasks for specific
        contexts.
        These models are associated with quality metrics that assess the
        outcomes of entity resolution tasks.
        Our study demonstrates the possibility of identifying abstract
        conditions invariant to specific solutions and data sets, which instead
        relate to the theoretical model used for evaluating entity resolution
        outcomes.
        This approach offers a novel perspective for understanding the
        performance of entity resolution tasks.
    \end{abstract}

    \begin{IEEEkeywords}
        Entity Resolution, Fellegi-Sunter, Algebraic Model, Metrics, Evaluation
    \end{IEEEkeywords}

    \section{Introduction}\label{sec:Introduction}
    Entity resolution is the task of determining whether multiple information
    refer to the same real-world item or not.
    More restrictive definitions place entity resolution as the task of
    identifying and linking representations of data from two or more
    sources~\cite{Qia17}.
    We share the opinion that identifying and linking data constitutes a more
    specialized process~\cite{Tal11}.
    It is broadly known that entity resolution goes by many names: data
    deduplication, merge-purge, named entity recognition and disambiguation,
    entity alignment, entity matching, and so on.
    Our paper uses a broader, deliberately vague definition in order to allow
    encompassing all of the above variants of entity resolution.
    
    Entity resolution solutions have been classified according to many criteria.
    The number of sources or the technological choice for the implementation are
    two example classification criteria.
    In this paper we examine another way of differentiating between entity
    resolution solutions.
    While it's undeniably interesting to study entity resolution implementations
    that use deep learning versus simple rule-based algorithms, the models that
    underlie the implementations appeal to us more.
    In general, models describe something using the theoretical tools at our
    disposal (usually mathematics).
    If we accept the previous statement, it's reasonable to say that multiple
    models describing the same thing provide us with varied perspectives over
    the described artifact.
    Models are ideally generic, allowing for the existence of varied practical
    manifestations of their described artifact.
    
    Entity resolution models describe entity resolution in two broad ways: as a
    matching task or as a clustering process.
    It is our hope to derive key insights that don't depend on data, purpose or
    implementation, relying instead on the entity resolution models themselves.
    In other words, the mere way we describe entity resolution (as matching or
    clustering) should point us toward the insights.

    When viewed as a matching problem, entity resolution is closely related to
    information retrieval.
    Perhaps as a hint to the validity of the matching perspective, entity
    resolution is performed most conveniently using competent information
    retrieval systems such as search engines or vector databases.
    On the other hand, we can see entity resolution as a task that clusters data
    which refers to the same real world entity.
    Using this lens, entity resolution becomes interesting for more abstract
    concerns such as knowledge management, computer vision or named entity
    recognition and disambiguation.
    One can intuit that even if we do have models for entity resolution that
    belong to these families, the terminologies they use to describe it are
    quite different with respect to one another.

    Finding terminology that applies to entity resolution in general (both for
    matching and clustering) allows us to pinpoint differences between entity
    resolution models more easily and more clearly.
    This leads to allowing finding insights that derive from models directly.
    To this end, we define model agnostic terms that describe entity resolution.
    
    To highlight insights derived from entity resolution models (consequently
    invariant with regard to other conditions), we will showcase the
    calibration process of an entity resolution solution using perspectives from
    two different models.
    One model will be a matching model, while the other will be a clustering
    model.
    The perspectives conferred by the two models are applied in the calibration
    process to reveal the insights we're after.

    To this end, we are interested in linking entity resolution quality metrics
    to model families (matching or clustering).
    This has two benefits in our opinion.
    The data structures used in the matching view over entity resolution differ
    from the ones used in a clustering context.
    This fact reveals an advantage when comparing entity resolution models,
    making it much easier to judge the usefulness of a given model for one
    application or another.
    Being able to compare models like this also facilitates finding conditions
    that are invariant with respect to the data or the purpose of the entity
    resolution task.
    Such conditions can then be used to easily optimize rule-based or machine
    learning entity resolution systems alike.
    
    We begin with a preliminary description focused on further detailing the
    goals of this paper.
    After briefly summarizing the work that relates to our paper, we introduce
    our own terminology that we use throughout the remaining sections.
    
    After finally revisiting our two chosen models for entity resolution, we
    delve into some findings from experiments made using a particular rule-based
    entity resolution algorithm.
    The chosen algorithm is merely an example. It may be replaced with any other
    as we take aim at what we may learn from the underlying entity resolution
    models, not from a particular application of those models.

    \section{Preliminaries \& Research Questions}\label{sec:Preliminaries & Questions}
    \input{research-questions}

    \section{Related Work}\label{sec:Related Work}
    
    The topic addressed in this paper intersects with a significant body of
    existing research.
    Specifically, it aligns closely with three primary categories: presentations
    of entity resolution systems, theoretical model syntheses for entity
    resolution, and analyses of evaluation metrics in the field of entity
    resolution.

    Papers introducing entity resolution systems are relevant to this study due
    to their common objective of standardizing entity resolution tasks and their
    evaluation methods.
    The majority of the referenced systems in this context offer several generic
    metrics for assessing entity resolution performance.

    At the dawn of the 21st century AD, FEBRL~\cite{febrl2002} emerged as one of
    the first extensible systems to tackle measuring entity resolution
    performance.
    It was succeeded by FEVER~\cite{fever2009} and OYSTER~\cite{oyster2012}.
    These systems have all paved the way to generalizing our understanding about
    entity resolution and to ever more improvements in the quality of entity
    resolution tasks.
    Later on, systems like `Papers with Code'~\cite{papwithcode2019} brought in
    a social dimension to how we compare the qualitative performance of entity
    resolution tasks.
    The systems that came after, such as JedAI~\cite{jedai2017} or Magellan
    \cite{magellan2020} resemble frameworks more than they do
    applications.
    Almost all systems are open-source and encourage social collaboration around
    entity resolution, too.
    
    Next, the syntheses on the theoretical models for entity
    resolution~\cite{fs1969,Ben2009Swoosh,Tal11} are invaluable resources.
    The models we present in this paper have been heavily documented
    elsewhere~\cite{Tal11,tal2013}.    
    We overview the models here to fill potential gaps in the reading flow of
    the paper more than to address another need.
    
    Taking a different tack on describing entity resolution in a generic,
    abstract way, there are studies that shine a procedural light over entity
    resolution~\cite{Pap19,Chen09}.
    These studies showcase the steps of the entity resolution process and the
    significance, challenges and benefits of each step.
    These studies show us that matching and clustering (additionally to being
    aspects of entity resolution) are steps in the entity resolution process.

    Lastly, we note syntheses that present numerous entity resolution metrics
    and their application~\cite{hitesh2012,graf2021frost,barnes2015practioner}.
    The current paper is very similar to these syntheses because it, too
    enumerates metrics and it, too attempts to use those metrics to gather
    deeper insights that would alleviate the burden of adopting entity
    resolution.
    We use this work to find the strongest associations of certain metrics with
    an entity resolution model.
    However, our approach is to discern between theoretical models and attempt
    to extract invariant conditions rooted in the model instead of simply using
    the metrics to evaluate the entity resolution result.

    \section{Background}\label{sec:Theoretical Background}
    \subsection{Terminology}\label{sec:Terminology}
    \input{terminology}
    
    \subsection{Formalizing Entity Resolution}\label{sec:Entity Resolution Formalization}
    \input{formalization}

    \subsection{Entity Resolution Models}\label{subsec:Entity Resolution Models}

    There are multiple entity resolution models and they range from ones based
    on complex networks and graph theory\cite{Li2020} to ones based on
    probabilities\cite{fs1969} or algebra\cite{Tal11,Ben2009Swoosh}.
    Broadly speaking, entity resolution models make up two large families:
    \textit{matching} and \textit{clustering} models.
    We are interested in the interplay between two models, one from each family.

    John R. Talburt provides an overview of entity resolution models in his book
    ``Entity Resolution and Information Quality''\cite{Tal11}.
    The main models presented there are the Fellegi-Sunter~\cite{fs1969} model,
    the Stanford Entity Resolution Framework~\cite{Ben2009Swoosh} model and the
    algebraic\cite{tal2007algebraic} model.
    Even though multiple entity matching models were published over time, the
    Fellegi-Sunter model still serves as the archetype for entity matching.
    The algebraic entity resolution model is the easiest to work with from the
    family of clustering models.

    The Fellegi-Sunter model is the main entity matching model.
    Although other significant entity matching models were developed in the
    meantime (from rule-based ones to deep learning enabled ones) entity
    resolution quality evaluation is still largely founded in the probabilistic
    approach described in the Fellegi-Sunter model.
    When measuring results using these metrics, a common experience is not being
    able to fully explain how the quality of the results output by a particular
    entity resolution process varies with the data sets the process operates on.
    A common attitude towards this phenomenon is to chalk it up to the
    characteristics of the underlying data and the size of the dataset.
    
    The second model we look into is the elegant algebraic model.
    The metrics most strongly associated with this model should be very familiar
    to all clustering afficionados.
    Other clustering models, including a particular projection of the more
    generic Stanford Entity Resolution Framework model, can use the same
    metrics.
    Clustering models describe entity resolution at a deeper level than matching
    models if only due to them capturing all four steps of the entity resolution
    process.

    Additionally to presenting the two models we want to answer whether they can
    be used in conjunction to analyse the same result.
    An observer may switch from a matching perspective to a more comprehensive
    one that leverages the clustering aspect of entity resolution.

    \subsection{Fellegi-Sunter Model}\label{subsec:Fellegi-Sunter Model}
    \input{fsm}

    \subsection{Algebraic Model}\label{subsec:Algebraic Model}
    \input{algebraic}

    \section{Experiments}\label{sec:Experiments}
    \input{experiments}

    \section{Conclusions}\label{sec:Conclusions}

    Entity resolution is a complex task that still holds many unknowns.
    When evaluating entity resolution results in practice it often happens that
    the results on control data sets are not the same as the results obtained
    on `real-world' data.
    In the end, those results speak about certain expectations that stem from
    the way we interpret data.

    We set out on a journey to find out whether entity resolution models might
    provide additional insights that we would use in our qualitative assessment
    of entity resolution.
    Our own perception is that entity resolution models are simply theoretical
    perspectives over the practical act of determining whether two entity
    references refer to the same real-world entity.

    Depending on the entity resolution model, we saw that we may have different
    data structures to take into account when running an entity resolution
    process: from lists of pairs to partitions over a set.
    Depending on the perspective and the data structures we choose, we can say
    different things about the data we analyse.
    We posited that we can even change our point of view from one perspective to
    another without any data loss.

    Our experiment setup was designed to find invariant conditions that might
    help reduce the time of picking a good entity resolution algorithm
    configuration by leveraging entity resolution models.
    One such condition is that \textbf{probabilistic recall is always going to
    be distorted when the size of the entity resolution result is much greater
    than the size of the ground truth.}
    Luckily, pairwise recall is the perfect antidote for this distortion.
    Probabilistic metrics might be cheap and easy to use, but use pairwise
    metrics when in doubt.

    Another invariant is that \textbf{cluster precision is a good counterweight
    to probabilistic and pairwise precision.}
    This leads to cluster metrics forming a harmonious complement to
    probabilistic metrics, pairwise metrics and to the Adjusted Rand Index (ARI)
    which is also pair-based.
    
    This leads us to our third invariant: \textbf{the Talburt-Wang Index and the
    cluster metrics on one side and the Adjusted Rand Index on the other usually
    agree only when there is a good balance between precision and recall.}
    The configuration value intervals where these metrics agree on a control
    data set provides us with a good estimation of the best configuration
    options for running an entity resolution algorithm.
    These configurations seem to be effective irrespective of the data we run
    entity resolution on, even if that data is purposefully designed to skew the
    results.

    % \section[future]{Future Work}\label{sec:future}

    The current paper covers only two models and there are more to cover.
    Existing models such as the one proposed by the Stanford Entity Resolution
    Framework\cite{Ben2009Swoosh} or graph theoretical models used frequently in
    entity alignment tasks are prime candidates.
    On the other hand, we can also propose new models based on recent
    developments in the field of machine learning and artificial intelligence.

    From an experimental perspective, we can expand our experiment base using
    more and more algorithms to find out whether the conjectures outlined in
    the current paper are worth proving formally.
    The other aspect that is left unresolved is the claim that probabilistic
    recall provides a distorted interpretation over the entity resolution result
    when the result size is significantly larger than the ground truth.
    Albeit challenging, experiments to verify this claim can and should be
    designed.

    Lastly, another significant dimension of entity resolution refers to the
    quantitative measurement of performance.
    Entity resolution is usually an expensive process in terms of computational
    resources.
    A solution that balances well the outcome quality with performance is
    desirable.

    \balance
    \bibliographystyle{ieeetr}
    \bibliography{er-general,er-related-work,er-additional-references,er-software}
\end{document}
