\documentclass[journal]{IEEEtran}

% Packages
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{algorithmic}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{array}
\usepackage{graphicx}
\usepackage{balance}
\usepackage{caption}

\captionsetup[table]{skip=6pt}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\graphicspath{ {./img/} }
\newcommand{\BibTeX}{\textrm{B \kern-.05em \textsc{i \kern-.025em b} \kern-.08em
T \kern-.1667em \lower.7ex \hbox{E} \kern-.125emX}}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

% Document
\begin{document}
    \title{A Tale of Two Entity Resolution Models}
    \author{
        \IEEEauthorblockN{
            Andrei Olar\IEEEauthorrefmark{1},
            Laura Dio\c san\IEEEauthorrefmark{2}
        }
        \IEEEauthorblockA{
            Faculty of Mathematics and Computer Science, Babe\c s-Bolyai University\\
            Email: 
                \IEEEauthorrefmark{1}andrei.olar@ubbcluj.ro,
                \IEEEauthorrefmark{2}laura.diosan@ubbcluj.ro
        }
    }

    \maketitle

    \theoremstyle{definition}
    \newtheorem{defn}{Definition}[section]
    
    \maketitle
    \begin{abstract}
        This paper examines entity resolution, the process of identifying if two
        information represent the same real-world entity.
        Despite well-established theoretical models in this field, challenges
        persist in selecting appropriate entity resolution tasks for specific
        contexts.
        These models are associated with quality metrics that assess the
        outcomes of entity resolution tasks.
        Our study demonstrates the possibility of identifying abstract
        conditions invariant to specific solutions and data sets, which instead
        relate to the theoretical model used for evaluating entity resolution
        outcomes.
        This approach offers a novel perspective for understanding the
        performance of entity resolution tasks.
    \end{abstract}

    \begin{IEEEkeywords}
        Entity Resolution, Fellegi-Sunter, Algebraic Model, Metrics, Evaluation
    \end{IEEEkeywords}

    \section{Introduction}\label{sec:Introduction}
    Entity resolution is the task of determining whether two information refer
    to the same real-world item or not.
    More restrictive definitions place entity resolution as the task of
    identifying and linking representations of data from two or more
    sources~\cite{Qia17}.
    However, we share the opinion that identifying and linking data constitutes
    a more specialized process~\cite{Tal11}.
    Besides leaving discussions concerning identity out of scope, we will not
    cover entity resolution classification on various well established criteria
    such as the number of sources and the technological choice underlying the
    solution.
    
    Because of its fundamental nature, entity resolution goes by many names:
    record linkage, data de-duplication, merge-purge, named entity recognition
    and disambiguation (or NERD), entity alignment or entity matching~\cite{Tal11,fever2009,alhelbawy2014}.
    The number of names is matched by the number of practical applications for
    entity resolution, ranging from linking medical records to assisting in
    medical diagnostics, to translation, to doing background checks for
    financial crime or to identifying plagiarism.
    Combining information from different media (sound, images, motion, smell,
    etc.) can also be regarded as a form of entity resolution when the purpose
    is to gather more information about the same real-world object.
    In this context, evaluating the quality of entity resolution using some well
    established criteria that don't vary based on application domain or solution
    seems interesting.

    With the current paper, our goal is to introspect how entity resolution
    models influence our perception over entity resolution results.
    The discussion is around judging the suitability of an entity resolution
    solution through the lens of two different models.
    We are interested in linking entity resolution quality metrics to models
    in particular because this shows us how we might tune an entity resolution
    solution in a way that does not vary with the application domain or choice
    of algorithmic approach (rule-based, machine learning and so on).
    
    We begin with a preliminary description focused on further detailing the
    goals of this paper.
    After briefly summarizing the work that relates to our paper, we introduce
    our own terminology that we use throughout the remaining sections.
    
    After finally revisiting our two chosen models for entity resolution, we
    delve into some findings from experiments made using a particular rule-based
    entity resolution algorithm.
    The chosen algorithm is merely an example. It may be replaced with any other
    as we take aim at what we may learn from the underlying entity resolution
    models, not from a particular application of those models.

    \section{Preliminaries \& Research Questions}\label{sec:Preliminaries & Questions}
    \input{research-questions}

    \section{Related Work}\label{sec:Related Work}
    
    The topic addressed in this paper intersects with a significant body of
    existing research.
    Specifically, it aligns closely with three primary categories: presentations
    of entity resolution systems, theoretical model syntheses for entity
    resolution, and analyses of evaluation metrics in the field of entity
    resolution.

    Papers introducing entity resolution systems are relevant to this study due
    to their common objective of standardizing entity resolution tasks and their
    evaluation methods.
    The majority of the referenced systems in this context offer several generic
    metrics for assessing entity resolution performance.

    At the dawn of the 21st century AD, FEBRL~\cite{febrl2002} emerged as one of
    the first extensible systems to tackle measuring entity resolution
    performance.
    It was succeeded by FEVER~\cite{fever2009} and OYSTER~\cite{oyster2012}.
    These systems have all paved the way to generalizing our understanding about
    entity resolution and to ever more improvements in the quality of entity
    resolution tasks.
    Later on, systems like `Papers with Code'~\cite{papwithcode2019} brought in
    a social dimension to how we compare the qualitative performance of entity
    resolution tasks.
    The systems that came after, resemble frameworks more than they resemble
    applications~\cite{magellan2020,jedai2017}.
    Almost all systems are open-source and encourage social collaboration around
    entity resolution, too.
    
    Next, the syntheses on the theoretical models for entity
    resolution~\cite{fs1969,Ben2009Swoosh,Tal11} are invaluable resources.
    The models we present in this paper have been heavily documented
    elsewhere~\cite{Tal11,tal2013}.    
    We overview the models here to fill potential gaps in the reading flow of
    the paper more than to address another need.
    
    Taking a different tack on describing entity resolution in a generic,
    abstract way, there are studies that shine a procedural light over entity
    resolution~\cite{Pap19,Chen09}.
    These studies showcase the steps of the entity resolution process and the
    significance, challenges and benefits of each step.
    These studies show us that matching and clustering (additionally to being
    aspects of entity resolution) are steps in the entity resolution process.

    Lastly, we note syntheses that present numerous entity resolution metrics
    and their application~\cite{hitesh2012,graf2021frost,barnes2015practioner}.
    The current paper is very similar to these syntheses because it, too
    enumerates metrics and it, too attempts to use those metrics to gather
    deeper insights that would alleviate the burden of adopting entity
    resolution.
    We use this work to find the strongest associations of certain metrics with
    an entity resolution model.
    However, our approach is to discern between theoretical models and attempt
    to extract invariant conditions rooted in the model instead of simply using
    the metrics to evaluate the entity resolution result.

    \section{Theoretical Background}\label{sec:Theoretical Background}
    \subsection{Terminology pre-requisites}\label{sec:Terminology}
    \input{terminology}
    
    \subsection{Formalizing Entity Resolution}\label{sec:Entity Resolution Formalization}
    \input{formalization}

    \subsection{Entity Resolution Models}\label{subsec:Entity Resolution Models}

    The representation of entity resolution results depends upon the theoretical
    model we use.
    There are multiple theoretical models available for entity resolution and
    they range from ones based on complex networks and graph theory\cite{Li2020}
    to ones based on probabilities\cite{fs1969} or
    algebra\cite{Tal11,Ben2009Swoosh}.

    John R. Talburt provides an overview of these models in his book ``Entity
    Resolution and Information Quality''\cite{Tal11}.
    The main models presented there are the Fellegi-Sunter~\cite{fs1969} model,
    the Stanford Entity Resolution Framework~\cite{Ben2009Swoosh} model and the
    algebraic\cite{tal2007algebraic} model.
    This paper aims to analyse two of the models described in that book with an
    aim to understand how they influence our ability to measure the quality of
    entity resolution.

    The Fellegi-Sunter model is the best known model for entity resolution.
    Most of quality evaluations in the entity resolution space are made using
    probabilistic metrics defined by this model.
    When measuring results using these metrics, a common experience is not being
    able to fully explain how the quality of the results output by a particular
    entity resolution process varies with the data sets the process operates on.
    A common attitude towards this phenomenon is to chalk it up to the
    characteristics of the underlying data and the size of the dataset.
    This paper attempts to find out if there are any conditions we might be able
    to extract that have to do with the entity resolution model instead.

    The second model this paper looks into is the elegant algebraic model.
    The metrics we most strongly associate with this model should be very
    familiar to data clustering afficionados.
    It seems to be a good complement for the Fellegi-Sunter model and we want to
    explore how in our experiments.

    Additionally to presenting the two models, the question of whether they can
    be used in conjunction to analyse the same result needs an answer.
    The paper describes how an observer can switch from a probabilistic
    perspective on entity resolution to an algebraic one.

    The complexity of the discussion and the presentational space required,
    force us to leave the Stanford Entity Resolution Framework model out of the
    conversation for the time being.
    This means that we won't go into the metrics that are more commonly linked
    to it either, such as the generalized merged distance, the basic merge
    distance or variation of information~\cite{Men10}, even if some of them
    might be applied (under certain circumstances) using the other two models.

    \subsection{Fellegi-Sunter Model}\label{subsec:Fellegi-Sunter Model}
    \input{fsm}

    \subsection{Algebraic Model}\label{subsec:Algebraic Model}
    \input{algebraic}

    \section{Experiments}\label{sec:Experiments}
    \input{experiments}

    \section{Conclusions}\label{sec:Conclusions}

    Entity resolution is a complex task that still holds many unknowns.
    When evaluating entity resolution results in practice it often happens that
    the results on control data sets are not the same as the results obtained
    on `real-world' data.
    In the end, those results speak about certain expectations that stem from
    the way we interpret data.

    We set out on a journey to find out whether entity resolution models might
    provide additional insights that we would use in our qualitative assessment
    of entity resolution.
    Our own perception is that entity resolution models are simply theoretical
    perspectives over the practical act of determining whether two entity
    references refer to the same real-world entity.

    Depending on the entity resolution model, we saw that we may have different
    data structures to take into account when running an entity resolution
    process: from lists of pairs to partitions over a set.
    Depending on the perspective and the data structures we choose, we can say
    different things about the data we analyse.
    We posited that we can even change our point of view from one perspective to
    another without any data loss.

    Our experiment setup was designed to find invariant conditions that might
    help reduce the time of picking a good entity resolution algorithm
    configuration by leveraging entity resolution models.
    One such condition is that \textbf{probabilistic recall is always going to
    be distorted when the size of the entity resolution result is much greater
    than the size of the ground truth.}
    Luckily, pairwise recall is the perfect antidote for this distortion.
    Probabilistic metrics might be cheap and easy to use, but use pairwise
    metrics when in doubt.

    Another invariant is that \textbf{cluster precision is a good counterweight
    to probabilistic and pairwise precision.}
    This leads to cluster metrics forming a harmonious complement to
    probabilistic metrics, pairwise metrics and to the Adjusted Rand Index (ARI)
    which is also pair-based.
    
    This leads us to our third invariant: \textbf{the Talburt-Wang Index and the
    cluster metrics on one side and the Adjusted Rand Index on the other usually
    agree only when there is a good balance between precision and recall.}
    The configuration value intervals where these metrics agree on a control
    data set provides us with a good estimation of the best configuration
    options for running an entity resolution algorithm.
    These configurations seem to be effective irrespective of the data we run
    entity resolution on, even if that data is purposefully designed to skew the
    results.

    % \section[future]{Future Work}\label{sec:future}

    The current paper covers only two models and there are more to cover.
    Existing models such as the one proposed by the Stanford Entity Resolution
    Framework\cite{Ben2009Swoosh} or graph theoretical models used frequently in
    entity alignment tasks are prime candidates.
    On the other hand, we can also propose new models based on recent
    developments in the field of machine learning and artificial intelligence.

    From an experimental perspective, we can expand our experiment base using
    more and more algorithms to find out whether the conjectures outlined in
    the current paper are worth proving formally.
    The other aspect that is left unresolved is the claim that probabilistic
    recall provides a distorted interpretation over the entity resolution result
    when the result size is significantly larger than the ground truth.
    Albeit challenging, experiments to verify this claim can and should be
    designed.

    Lastly, another significant dimension of entity resolution refers to the
    quantitative measurement of performance.
    Entity resolution is usually an expensive process in terms of computational
    resources.
    A solution that balances well the outcome quality with performance is
    desirable.

    \balance
    \bibliographystyle{ieeetr}
    \bibliography{er-general,er-related-work,er-additional-references,er-software}
\end{document}
