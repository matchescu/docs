\documentclass[journal]{IEEEtran}

% Packages
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{algorithmic}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{cite}
\usepackage{array}
\usepackage{graphicx}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\graphicspath{ {./img/} }
\newcommand{\BibTeX}{\textrm{B \kern-.05em \textsc{i \kern-.025em b} \kern-.08em
T \kern-.1667em \lower.7ex \hbox{E} \kern-.125emX}}
\usepackage{balance}

% Document
\begin{document}
    \title{Lessons Learned While Comparing Two Entity Resolution Models}
    \author{Andrei Olar}

    \maketitle

    \theoremstyle{definition}
    \newtheorem{defn}{Definition}[section]
    
    \maketitle
    \begin{abstract}
        This paper examines entity resolution, the process of identifying if two
        pieces of information represent the same real-world entity.
        Despite well-established theoretical models in this field, challenges
        persist in selecting appropriate entity resolution tasks for specific
        contexts.
        These models are associated with quality metrics that assess the
        outcomes of entity resolution tasks.
        Our study demonstrates the possibility of identifying abstract
        conditions invariant to specific solutions and data sets, which instead
        relate to the theoretical model used for evaluating entity resolution
        outcomes.
        This approach offers a novel perspective for understanding the
        performance of entity resolution tasks.
    \end{abstract}

    \begin{IEEEkeywords}
        Entity Resolution, Fellegi-Sunter, Algebraic Model, Metrics, Evaluation
    \end{IEEEkeywords}

    \section{Introduction}\label{sec:introduction}
    Entity resolution is the task of determining whether two information refer
    to the same real-world item or not.
    More restrictive definitions place entity resolution as the task of
    identifying and linking representations of data from two or more
    sources~\cite{Qia17}.
    However, we share the opinion that identifying and linking data constitutes
    a more specialized process~\cite{Tal11}.
    We also leave aside any classification of entity resolution algorithms based
    on number of sources.
    The task of gathering information about a generic pound of potatoes across
    various marketplaces is still an entity resolution task, in our view.
    Whether the information about marketplaces and the potatoes that find
    themselves passing through there is available in one or more places strikes
    us as non-consequential, too.
    
    Precisely because it is a fundamental problem, entity resolution goes by
    many names: record linkage, data de-duplication, merge-purge, named entity
    recognition and disambiguation (or NERD), entity alignment or entity
    matching~\cite{Tal11,fever2009,alhelbawy2014}.
    Entity resolution also has many practical applications ranging from linking
    medical records to diagnosing diseases or ailments, to translation, to doing
    background checks for financial crime or to identifying plagiarism.
    Combining information from different media (sound, images, motion, smell,
    etc.) can also be regarded as a form of entity resolution when the purpose
    is to gather more information about the same real-world object.
    When there is such a wide array of past, present and future applications,
    evaluating entity resolution quality seems important.

    This paper is an introspection on how entity resolution theoretical models
    influence our perception of entity resolution results and tasks.
    We attempt to discuss whether entity resolution solutions themselves can be
    deemed more or less suitable within a context based on their results.
    In doing so we're also interested to see how metrics used for evaluating
    entity resolution result quality complement one another.
    Partly in order to answer this last question, we are looking into ways in
    which two differnt entity resolution models might provide different insights
    into the quality of the same entity resolution result.
    
    We begin by exploring a few preliminaries that detail the goals of this
    paper.
    After briefly summarizing the work that relates to our paper, we introduce
    terminology and a mental model that we use throughout the rest of the paper.
    Afterwards, we briefly introduce the theoretical models for entity
    resolution that we chose for our analysis.
    We then run a few experiments using an entity resolution solution of choice
    and present our findings using three well known data sets and one generated
    data set.
    Lastly, we discuss our observations, pointing out invariant conditions that
    do not seem to be related to the choice of data set.

    \section[preliminaries-questions]{Preliminaries \& Research Questions}
    \label{sec:preliminaries-questions}
    \input{research-questions}
    
    \section{Related Work}\label{sec:related}
    
    The topic addressed in this paper intersects with a significant body of
    existing research.
    Specifically, it aligns closely with three primary categories: presentations
    of entity resolution systems, theoretical model syntheses for entity
    resolution, and analyses of evaluation metrics in the field of entity
    resolution.

    Papers introducing entity resolution systems are relevant to this study due
    to their common objective of standardizing entity resolution tasks and their
    evaluation methods.
    The majority of the referenced systems in this context offer several generic
    metrics for assessing entity resolution performance.

    At the dawn of the 21st century, FEBRL~\cite{febrl2002} emerged as one of the
    first extensible systems to tackle measuring entity resolution performance.
    It was succeeded by FEVER~\cite{fever2009} and OYSTER~\cite{oyster2012}.
    These systems have all paved the way to generalizing our understanding about
    entity resolution and to ever more improvements in the quality of entity
    resolution tasks.
    Later on, systems like `Papers with Code'~\cite{papwithcode2019} brought in
    a social dimension to how we compare the qualitative performance of entity
    resolution tasks.
    The systems that came after, resemble frameworks more than they resemble
    applications~\cite{magellan2020,jedai2017}.
    Almost all systems are open-source and encourage social collaboration around
    entity resolution, too.
    
    Next, the syntheses on the theoretical models for entity
    resolution~\cite{fs1969,Ben2009Swoosh,Tal11} are invaluable resources.
    The models we present in this paper have been heavily documented
    elsewhere~\cite{Tal11,tal2013}.    
    We overview the models here to fill potential gaps in the reading flow of
    the paper more than to address another need.
    
    Taking a different tack on describing entity resolution in a generic,
    abstract way, there are studies that shine a procedural light over entity
    resolution~\cite{Pap19,Chen09}.
    These studies showcase the steps of the entity resolution process and the
    significance, challenges and benefits of each.
    These studies show us that matching and clustering (additionally to being
    aspects of entity resolution) are steps in the entity resolution process.

    Lastly, we note syntheses that present numerous entity resolution metrics
    and their application~\cite{hitesh2012,graf2021frost,barnes2015practioner}.
    This paper is very similar to these syntheses because it, too enumerates
    metrics and it, too attempts to use those metrics to gather deeper insights
    that would alleviate the burden of adopting entity resolution.
    We use this work to find how strong is the association between certain
    metrics to an entity resolution model.
    However, our approach is to discern between theoretical models and attempt
    to extract invariant conditions rooted in the model instead of simply using
    the metrics to evaluate the entity resolution result.

    \section[terminology]{Terminology}\label{sec:terminology}
    \input{terminology}
    
    \section{Formalizing Entity Resolution}\label{sec:entity-resolution}
    \input{formalization}

    \section[models]{Entity Resolution Models}\label{sec:models}

    The representation of entity resolution results depends upon the theoretical
    model we use.
    There are multiple theoretical models available for entity resolution and
    they range from ones based on complex networks and graph theory\cite{Li2020}
    to ones based on probabilities\cite{fs1969} or
    algebra\cite{Tal11,Ben2009Swoosh}.

    John R. Talburt provides an overview of these models in his book ``Entity
    Resolution and Information Quality''\cite{Tal11}.
    This paper aims to analyse two of the models described in that book with an
    aim to understand how they influence our ability to measure the quality of
    entity resolution.

    The Fellegi-Sunter model is the best known model for entity resolution.
    Most of quality evaluations in the entity resolution space are made using
    probabilistic metrics defined by this model.
    When measuring results using these metrics, a common experience is not being
    able to fully explain how the quality of the results output by a particular
    entity resolution process varies with the data sets the process operates on.
    A common attitude towards this lack of understanding is to chalk things off
    to the characteristics of the underlying data and the size of the dataset.
    This paper attempts to find out if there aren't some things we might be able
    to infer regardless of those two qualities of the underlying data.

    The second model this paper looks into is the elegant algebraic model.
    The metrics it makes available to us are familiar metrics for anyone working
    with graph networks or clusters of any kind.
    It seems to be a good complement for the Fellegi-Sunter model.
    This paper attempts to find out if the algebraic model can complement the
    weaknesses of the Fellegi-Sunter model.
    Furthermore, the paper looks into ways in which an observer can switch from
    a probabilistic perspective over the entity resolution results corresponding
    to the Fellegi-Sunter model to an algebraic perspective.

    Discussing these aspects is complex and takes enough space to warrant adding
    a third model to the conversation inopportune.

    \subsection[fsm]{Fellegi-Sunter Model}\label{subsec:fsm}
    \input{fsm}

    \subsection[algebraic]{Algebraic Model}\label{subsec:algebraic}
    \input{algebraic}

    \subsection{From Probabilities to Algebra}\label{subsec:fsm-alg}
    \input{convert}
        
    \section{Experiments}\label{sec:experiments}
    \input{experiments}

    \section[conclusion]{Conclusions}\label{sec:conclusions}

    \textcolor{green}{tb adaugata o fraza despre context (ER) si scipul mare al studiului. Abia apoi vin evidentiate cele 2 mari concluzii/zontributii: maparea unui model in altul si analiza dpdv al metricilor}

    We compared two perspectives over entity resolution in theoretical and
    practical terms.
    Our declared objective was to find invariant conditions that might help us
    bridge the gap between computer knowledge and user expectation.

    The data structures involved using the Fellegi-Sunter model for entity
    resolution revolve around pairs of entity references, whereas those that
    are specific to the algebraic model are centered around sets and partitions
    over sets.
    One interesting finding is that a transition from the Fellegi-Sunter model
    to the algebraic model is possible using the Union-Find data structure and
    a simplified version of Kruskal's algorithm.

    Having this knowledge we ran an experiment using the \texttt{ppjoin}
    algorithm on a generated data set.
    By looking at the results we saw how theoretical models provide different
    perspectives on the same algorithm.
    Having this outlook on things, we were able to glean insights that have
    nothing to do with the algorithm but with the perspectives themselves.

    To see whether the perspectives change if the underlying data changes, we
    ran the experiment on three different benchmark datasets.
    A first conjecture that arises after doing so states that the Fellegi-Sunter
    model for entity resolution provides a perspective over the quality of the
    entity resolution results which is overly optimistic in evaluating recall.
    This leads to higher F1 scores and possibly to wrong conclusions when
    comparing entity resolution solutions using the F1 score.

    The second conjecture is that we can safely use the Talburt-Wang Index to
    find input configurations of the entity resolution task in which it performs
    clustering well.
    The Adjusted Rand Index can be used in the same way to find input conditions
    where the entity resolution task performs matching well.

    We will not draw any conclusion with regard to extrapolating observations on
    smaller sets to larger sets of data or to the overall performance of the
    algorithm even though the data suggests that at least the ballpark stays the
    same.
    In order to make such claims, we need to design and run experiments using
    other entity resolution algorithms.

    \section[future]{Future Work}\label{sec:future}

    The current paper covers only two models and there are more to cover.
    Existing models such as the one proposed by the Stanford Entity Resolution
    Framework\cite{Ben2009Swoosh} or graph theoretical models used frequently in
    entity alignment tasks are prime candidates.
    On the other hand, we can also propose new models based on recent
    developments in the field of machine learning and artificial intelligence.

    From an experimental perspective, we can expand our experiment base using
    more and more algorithms to find out whether the conjectures outlined in
    the current paper are worth proving.
    Given the costs of fine-tuning an entity resolution system, a good step
    forward seems to be finding more invariants that would allow us to draw
    conclusions on entity resolution system using small data sets.

    Lastly, another significant dimension of entity resolution refers to the
    quantitative measurement of performance.
    Let us not forget that entity resolution is usually a very expensive process
    in terms of the computational resources it uses.
    Therefore a solution that balances well the outcome quality with performance
    is desirable.

    \textcolor{green}{things that are confused:\\
    1. model vs. algorithm vs. task related to ER\\
    2. scopul art: sa evidentiem mapparea FS vs model algebric sau sa analizam critic metricile (pt ca doar astfel se poate face o alegere eficienta a modelului de ER folosit, desi tb tinut cont ca suntem intr-un mediu oarecum controlat; unde avem niste dataset-uri limitate, nu de tip openworld pt care nu se calculeaza efectiv metricile, ci se estimeaza cumva - a se vedea problema despre bridging
    the reality-ideality gap in entity resolution, where high performance on benchmark datasets often does not
    translate into the real world \href{https://arxiv.org/pdf/2205.05889.pdf}{link}) sau ambele? :D\\
    3. in fc de scopul de la pct 2 tb adaugat in introducere info despre contributie, precum si in Rel Work\\
    4. def pt "perspectiva" (de sine statatoare sau relativ la un model sau la un algo de ER); \\
    5. def pt "input config" \\
    6. de verificat daca folosirea notiunii de "invariant" se poate demonstra si teoretic, nu doar empiric\\
    8. tb spus de ce nu s-au inclus si alte metrici (de ex GMD)\\
    9. tb spus ceva despre class imbalance (ce influenta are asupra metricilor faptul ca sunt doar cateva elemente aliniate/duplicate si multe elemente nealiniate)\\
    10.
    }
    
    \bibliographystyle{ieeetr}
    \bibliography{er-general,er-related-work,er-additional-references,er-software}
\end{document}
