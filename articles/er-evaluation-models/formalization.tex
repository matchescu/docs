In a broad sense, the entity resolution process is usually comprised of four
different steps~\cite{Pap19,Tal11}:

\begin{itemize}
    \item \textit{entity reference extraction} --- the first phase of entity
    resolution deals with extracting entity references from input data
    sources, as detailed in Section~\ref{sec:Terminology};
    \item \textit{blocking} and \textit{filtering} --- at this stage, the
    entity resolution task groups in the same `block' entities that share
    similar traits and then within each block all entities that cannot
    possibly match are filtered \textit{out}; the intent here is to allow
    entity resolution tasks to work with large amounts of data~\cite{Pap19};
    \item \textit{matching} --- one of the defining activities of the entity
    resolution process, it consists of comparing entity references to one
    another;
    \item \textit{clustering} --- the other defining entity resolution
    activity which collects matching references in entity profiles.
\end{itemize}

We start our journey into the formalization of entity resolution with
formalizing entity reference extraction using the notions from
Section~\ref{sec:Terminology}.

Given:
\begin{itemize}
    \item $n \in \mathbb{N}^*$ pairs ($S_i$, $n_i$), $1 \leq i \leq n$, $n_i \in \mathbb{N}$, 
    where $S_i$ is a data source and $n_i$ is the number of messages in
    $S_i$,
    \item $m_i \in \mathbb{N}^*$ traits $t_{ij}$, $1 \leq j \leq m_i$ for each
    information source $S_i$ so that
    \item each trait $t_{ij}$ can generate at most $a_{ij} \in \mathbb{N}^*$
    attributes,
\end{itemize}
an entity resolution process $ER$ applies each trait $t_{ij}$ onto the source
$S_i$, $1 \leq i \leq n$, $1 \leq j \leq m_i$, in order to extract
$r_{{S_i}k}$ entity references where
$0 \leq k \leq n_i \cdot \sum^{m_i}_{j=1}a_{ij}$.

Next, we denote with $A$ the domain of all possible attributes that can be
used by $ER$.

In this context, let $r_{{S_i}{k_j}}$ denote the $k_j$th, $1 \leq j \leq k$
entity reference extracted from the source $S_i$.
Then $r_{{S_i}{k_j}}$ is a tuple
\[
    (a_r, r \in \mathbb{N}^*, a_r \in A), r_{{S_i}{k_j}} \in A^r
\]
where $r$ varies for each $k_j$.

We see now the advantage of defining traits and the organizing principle as
external to the data source in the simple formalization of entity references.
The definition of traits materializes only upon extracting entity references
$r_{{S_i}{k_j}}$ with $ER$.
The output domain of this function is the domain of all attributes in the source
$S_i$.
We denote this domain with $A_{{S_i}{k_j}}$.

A trait can then be declared as a function:

\[
    t: S_i \rightarrow A_{{S_i}{k_j}}^x\textrm{, where }x \in \mathbb{N}^*
\]
and $x$ varies with $k_j$.

During the extraction process, \textit{ER}'s traits lead to the construction
of the domain of entity references:

\[
    Ref = \bigcup_{i \in N^*,1 \leq j \leq k} r_{{S_i}{k_j}}
    \textrm{, with } r \textrm{, }S \textrm{ and } k \textrm{ specified above.}
\]

$Ref$ is the outcome of the entity reference extraction phase.
Once $Ref$ has been determined, entity resolution can continue agnostic of the
input information sources.

Every type of entity resolution task can be made to work on such an input
domain.
De-duplication tasks that use a single data source work out of the box.
Record linking tasks that use two or more data sources can embed an
attribute that identifies the data source of each entity reference~\cite{Pap19}.
Regardless of the optics, the input domain contains only entity references.
The relevance of the original data source of an entity reference rests with
the entity resolution task and its matching and clustering algorithms.

The output of entity resolution is always a collection of entity profiles.
We can define the output domain of entity resolution:

\[
    Res=\{P_y \mid y \in \mathbb{N^*}, P_y \in P\}
\]

\noindent
as the domain of collections of entity profiles, where \textit{P} represents the
domain of entity profiles.
The domain of entity profiles is specified for each entity resolution model.

This specification, finally, allows us to formalize entity resolution itself as a function:

\[
    e(r_1, r_2, \ldots, r_n): Ref^n \rightarrow Res\text{, where }n\in\mathbb{N^*}
\]

\noindent
which takes in a sequence of entity references and outputs a collection of
entity profiles.

Note that $Res$ is always going to be a collection containing unique entity
profiles in any theoretical model of entity resolution because of the nature
of the entity resolution problem.
Entity resolution disambiguates information by definition, making it impossible
for identical items to be a part of a correct output.
This should not be taken to mean that the result of an entity resolution process
will always be represented as a set data structure.

If $Res$ is the domain of all collections of entity profiles, one of
the collections that are part of $Res$ must be the collection of entity
profiles that best resembles our understanding of reality.

\begin{defn}
    We define the \textit{ground truth} \textbf{G} over the entity reference
    domain \textit{Ref} as the entity resolution result comprised of entity
    profiles:
    \[
        \{P_g \mid g \in \mathbb{N^*}\}\textrm{, such that:}
    \]
    \begin{itemize}
        \item each $P_g$ describes an entity completely using the available
        entity references from $Ref$, and
        \item there are no entity references in \textit{Ref} which are not a
        part of a $P_g \in G$.
    \end{itemize}
\end{defn}

In other words the ground truth is the ideal entity resolution result for 
the given input data, in a context, from a perspective.
Knowing this, we can formalize entity resolution quality generically with
respect to the ground truth.

\begin{defn}
Given an entity resolution \textit{e} and the ground truth \textit{G} for
the entity reference domain $Ref$, a \textit{quality metric} is an
idempotent function:
\[
    q: Res^2 \rightarrow \mathbb{R}
\]
which scores how similar the result of \textit{e} is to \textit{G}.
\end{defn}

In practice, we should strive to implement quality metric as \textit{pure}
functions, guarding their execution from any side-effects specific to
running a program on a computer.

We stated above that specific definitions of $Res$ can only be given per each
entity resolution model as each model presents a unique perspective on what
entity resolution is.
We also know from the previous definition that $Res^2$ is the input domain of
quality metrics.
Then a logical consequence is that a set of quality metrics
$Q = \{q_z \mid z \in \mathbb{N}\}$ can only be defined in the context of an
entity resolution model.
In other words, quality metrics are linked to entity resolution models through
the specification of the $Res$ domain.

An immediate corollary of the above proposition is that if two entity resolution
models represent entity profiles in the same way, the same quality metrics can
be used under both models.

Going further with this logic, if the entity resolution $e_1$ can be evaluated
using the quality metrics in $Q_1$ and $e_2$ can be evaluated using the quality
metrics in $Q_2$ such that $Q_1 \cap Q_2 \neq \emptyset$ then we have a set of
quality metrics $Q_\cap = Q_1 \cap Q_2$ that allows us to compare $e_1$ and
$e_2$ based on $Q_\cap$.