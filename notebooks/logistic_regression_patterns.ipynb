{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Entity Resolution using Logistic Regression\n",
    "\n",
    "The other notebook on Logistic Regression shows the default approach when using\n",
    "this type of model to perform entity matching.\n",
    "In this notebook, we're giving the approach a different spin.\n",
    "We'll encode raw similarity values resulted from encoding attributes with all\n",
    "possible patterns of the values of the output classes (0 and 1).\n"
   ],
   "id": "940700d100283c33"
  },
  {
   "cell_type": "code",
   "id": "ca31fd0d-16e8-4b69-ae32-3cfa3d13cd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:20:59.109423Z",
     "start_time": "2024-10-09T12:20:58.876974Z"
    }
   },
   "source": [
    "import os\n",
    "import polars as pl\n",
    "\n",
    "from matchescu.matching.entity_reference import (\n",
    "    RawComparison,\n",
    ")\n",
    "from matchescu.matching.ml.datasets import CsvDataSource, Traits"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "'Constant' definition. Change the values here to use a different dataset.",
   "id": "86ec9eb605aa9917"
  },
  {
   "cell_type": "code",
   "id": "ca59198f-45a6-48da-b119-b1e5d18d81a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:21:28.288234Z",
     "start_time": "2024-10-09T12:21:28.284746Z"
    }
   },
   "source": [
    "DATADIR = os.path.abspath(\"../../data\")\n",
    "LEFT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Abt.csv\")\n",
    "RIGHT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Buy.csv\")\n",
    "GROUND_TRUTH_PATH = os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The sources of information can be structured in any way. However, when we read\n",
    "from the data source we expect to be able to refer to discrete pieces of\n",
    "information.\n",
    "The important bit is to have a decent feature extraction process that is able to\n",
    "produce relatively uniformly shaped entity references. That's what `Traits()`\n",
    "do. That way we can get a neat matching process going.  "
   ],
   "id": "94a19e6978f60a76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:21:30.096418Z",
     "start_time": "2024-10-09T12:21:30.085390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up abt extraction\n",
    "abt_traits = list(Traits().int([0]).string([1, 2]).currency([3]))\n",
    "abt = CsvDataSource(name=\"abt\", traits=abt_traits).read_csv(LEFT_CSV_PATH)\n",
    "# set up buy extraction\n",
    "buy_traits = list(Traits().int([0]).string([1, 2, 3]).currency([4]))\n",
    "buy = CsvDataSource(name=\"buy\", traits=buy_traits).read_csv(RIGHT_CSV_PATH)\n",
    "# set up ground truth\n",
    "gt = set(\n",
    "    pl.read_csv(\n",
    "        os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\"),\n",
    "        ignore_errors=True,\n",
    "    ).iter_rows()\n",
    ")"
   ],
   "id": "83b92f4b0ad5b632",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For Logistic Regression we want similarities to return real values between 0 and\n",
    "1."
   ],
   "id": "7256f6f27121c8a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:22:09.048697Z",
     "start_time": "2024-10-09T12:22:09.045315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cmp_config = (\n",
    "    RawComparison()\n",
    "    .levenshtein(\"name\", 1, 1, threshold=0.8)\n",
    "    .levenshtein(\"description\", 2, 2, threshold=0.8)\n",
    "    .exact(\"price\", 3, 4)\n",
    ")"
   ],
   "id": "9a8c40f7a87a6ed5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, it's time to instantiate the `RecordLinkageDataSet` with a 'pattern\n",
    "encoded' sampling strategy."
   ],
   "id": "f119313d74584337"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:36:53.376226Z",
     "start_time": "2024-10-09T12:35:03.415842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matchescu.matching.ml.datasets import RecordLinkageDataSet\n",
    "\n",
    "r = 2  # y contains 0 or 1\n",
    "ds = RecordLinkageDataSet(abt, buy, gt).pattern_encoded(cmp_config, r).cross_sources()\n",
    "y = ds.target_vector.to_numpy()\n",
    "X = ds.feature_matrix.to_numpy()"
   ],
   "id": "fbeabd2e052f94d2",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that we now have $r^m$ features instead of $m$, where $m$ is the number\n",
    "of comparisons we make and $r$ the number of possible results. The question\n",
    "really is whether this is useful or not."
   ],
   "id": "783ba681d505d8a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:36:56.253414Z",
     "start_time": "2024-10-09T12:36:56.251309Z"
    }
   },
   "cell_type": "code",
   "source": "print(X.shape, y.shape)",
   "id": "34dfd7f7c150049a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1180452, 8) (1180452,)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The feature matrix now contains values based on similarities, but which have\n",
    "been encoded to express what would happen if all attribute similarities were to\n",
    "predict a pattern of matching or non-matching.\n",
    "We'll use SciKit Learn's `train_test_split` to split our data into training\n",
    "and test sets.\n",
    "We can now train a Logistic Regression model using our feature matrix."
   ],
   "id": "275e706feb9e71c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:37:00.098545Z",
     "start_time": "2024-10-09T12:36:59.531005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6)\n",
    "y_ratio = len(y[y == 1]) / len(y)\n",
    "y_train_ratio = len(y_train[y_train == 1]) / len(y_train)\n",
    "y_test_ratio = len(y_test[y_test == 1]) / len(y_test)\n",
    "\n",
    "# the model is adjusted to handle the class imbalance specific to ER datasets\n",
    "model = LogisticRegression(class_weight={0: 1, 1: 9})\n",
    "model = model.fit(X_train, y_train)"
   ],
   "id": "1937dd3ee913f9cc",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Logistic regression training is much faster than Fellegi-Sunter pattern matching\n",
    "and on par with Naive Bayes."
   ],
   "id": "f9d5564cdf5d97ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:37:03.101335Z",
     "start_time": "2024-10-09T12:37:03.085016Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred = model.predict(X_test)",
   "id": "41d5a203a0b3e7b2",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can compute our metrics.",
   "id": "18e713f96a0bbccb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T12:37:04.919463Z",
     "start_time": "2024-10-09T12:37:04.839248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "p = precision_score(y_test, y_pred)\n",
    "r = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"precision={p}\", f\"recall={r}\", f\"F1={f1}\")"
   ],
   "id": "433106402b5eccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.23448275862068965 recall=0.4657534246575342 F1=0.3119266055045872\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Comparing this with standard logistic regression shows us only marginal\n",
    "improvements - similar to what we saw when using polynomials. This is expected\n",
    "because we've basically only combined feature values in various ways."
   ],
   "id": "635b982829490e88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
